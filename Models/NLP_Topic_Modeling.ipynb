{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPIC MODELING FOR DOTIN'S PSYCHOMETRIC SURVEY QUESTIONS USING LDA & BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/Ergo/Desktop/Git_Dotin/Dotin-Columbia-Castone-Team-Alpha-/Data/Extra/psyc_data.csv', \n",
    "                   error_bad_lines=False, index_col=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NOTE: WE NEED SOME BETTER DATA PREPROCESSING - THIS IS TO BE DONE##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NAs\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove special characters from item column\n",
    "df['item'] = df['item'].replace('\\W', ' ')\n",
    "df['item']= df['item'].replace('+AC0-', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary step to get the preprocessing functions running- for some reason it's not \n",
    "#considering all items as strings\n",
    "df['item']=df['item'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "np.random.seed(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizing and stemming text - we'll need to improve upon these\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = train['item'].map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary for processed_words with nr of times word appears in the dataset\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove very rare (words appearing less than 10 times) and common words \n",
    "#(words appearing in more than 10% of docs)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bag of words corpus for the dictionary\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA ON BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train LDA model using BoW created\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                       num_topics=10, \n",
    "                                       id2word = dictionary, \n",
    "                                       passes = 2, \n",
    "                                       workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the words occuring in each topic and their relative weight\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "###HERE WE NEED TO GIVE THESE OUTPUT TOPICS SOME NAMES###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POTENTIAL TOPIC CLASSIFICATION:\n",
    "* Topic 0: TBD\n",
    "* Topic 1: TBD\n",
    "* Topic 2: TBD\n",
    "* Topic 3: TBD\n",
    "* Topic 4: TBD\n",
    "* Topic 5: TBD\n",
    "* Topic 6: TBD\n",
    "* Topic 7: TBD\n",
    "* Topic 8: TBD\n",
    "* Topic 9: TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING LDA ON THE CORPUS TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on one document from the test set\n",
    "num = 100\n",
    "unseen_document = test.item[num]\n",
    "print(unseen_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing step for the unseen document\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5))) #you can change the number to be anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for all data in the test dataset\n",
    "test_unseen = list(test['item'])\n",
    "\n",
    "for i in range(len(test_unseen)):\n",
    "    test_unseen_dict=[]\n",
    "    bow_vector=dictionary.doc2bow(preprocess(i))\n",
    "    test_unseen_dict.append(bow_vector)\n",
    "return test_unseen_bow_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_unseen_bow_vector:\n",
    "    for index, score in sorted(lda_model[i], key=lambda tup: -1*tup[1]):\n",
    "        print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index)))\n",
    "        \n",
    "        ###still needs to be completed###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING THE LDA MODEL ON OUR QUESTION DATASET (AKA UNSEEN DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call in test dataset (our question dataset) and see LDA model performance\n",
    "test_df=pd.read_csv('C:/Users/Ergo/Desktop/Git_Dotin/Dotin-Columbia-Castone-Team-Alpha-/Data/Extra/survey_questions_with_id_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn questions to list\n",
    "test_documents = list(test_df['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data preprocessing step for the test dataset\n",
    "for i in range(len(test_documents)):\n",
    "    testdoc_unseen_dict=[]\n",
    "    bow_vector=dictionary.doc2bow(preprocess(i))\n",
    "    test_unseen_dict.append(bow_vector)\n",
    "return testdoc_unseen_bow_vector\n",
    "\n",
    "for i in testdoc_unseen_bow_vector:\n",
    "    for index, score in sorted(lda_model[i], key=lambda tup: -1*tup[1]):\n",
    "        print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index)))\n",
    "        \n",
    "        \n",
    "###still needs to be completed###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
